{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание по БиоИнформатике №2\n",
    "\n",
    "*Работа выполнена студентом 193 группы Боревским Андреем*\n",
    "\n",
    "### I. Обработка данных\n",
    "----\n",
    "\n",
    "**Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import tensorflow.compat.v1 as tf\n",
    "import time\n",
    "import math\n",
    "import sys\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Constants**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "INTERVAL = 200\n",
    "SUB_INTERVAL = 100\n",
    "SIZE = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Intersect and Difference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bedtools subtract -a genome.bed -b H3F3A.merge.hg19.bed Quadruplexes_LI_K.bed > negative.bed\n",
    "!bedtools intersect -a genome.bed -b H3F3A.intersect_with_Quadro.bed > positive.bed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setting the size**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def magic_function(file_name, out_name, INT):\n",
    "    df = pd.read_csv(file_name, header=None, sep='\\t')\n",
    "\n",
    "    df.drop(df[(df[2] - df[1]) < INT].index, inplace=True)\n",
    "    df['middle'] = (df[2] - df[1]) / 2 + df[1]\n",
    "    df.start = df.middle - INT / 2\n",
    "    df.end = df.middle + INT / 2\n",
    "    df.drop('middle', axis=1, inplace=True)\n",
    "\n",
    "    df.to_csv(out_name, header=None, sep='\\t', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "magic_function(\"positive.bed\", \"pos_cut.bed\", INTERVAL)\n",
    "magic_function(\"negative.bed\", \"neg_cut.bed\", INTERVAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fasta**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!twoBitToFa http://hgdownload.cse.ucsc.edu/gbdb/hg19/hg19.2bit -bed=neg_cut.bed ac_negative.fa\n",
    "!twoBitToFa http://hgdownload.cse.ucsc.edu/gbdb/hg19/hg19.2bit -bed=pos_cut.bed ac_positive.fa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readInputs(f1,f2):\n",
    "    lines_pos = open(f1).readlines()\n",
    "    lines_neg = open(f2).readlines()\n",
    "\n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    for l in convertLines(lines_pos):\n",
    "        X.append(l)\n",
    "        Y.append(1)\n",
    "    for l in convertLines(lines_neg):\n",
    "        X.append(l)\n",
    "        Y.append(0)\n",
    "\n",
    "    return X,Y\n",
    "\n",
    "\n",
    "def convertLines(lines):\n",
    "    newLines = []\n",
    "    for line in lines:\n",
    "        newline = []\n",
    "        counter = 0\n",
    "        if line[0] == '>': continue\n",
    "        if len(line) != SIZE + 1: continue\n",
    "        for c in line.strip():\n",
    "            counter += 1\n",
    "            if c == 'A' or c == 'a':\n",
    "                v = [1,0,0,0]\n",
    "            elif c == 'C' or c == 'c':\n",
    "                v = [0,1,0,0]\n",
    "            elif c == 'G' or c == 'g':\n",
    "                v = [0,0,1,0]\n",
    "            elif c == 'T' or c == 't':\n",
    "                v = [0,0,0,1]\n",
    "            else:\n",
    "                v = [0,0,0,0]\n",
    "            newline.append(v)\n",
    "        newLines.append(newline)\n",
    "    return newLines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = readInputs(\"ac_positive.fa\", \"ac_negative.fa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Обучение нейронной сети: pre-processing\n",
    "-----\n",
    "\n",
    "**Splitting the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Magic code of magic NN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = 'jasperz'\n",
    "\n",
    "class NetworkModel:\n",
    "    tf.disable_v2_behavior()\n",
    "    def __init__(self, file_to_load = None):\n",
    "        tf.reset_default_graph()\n",
    "        self.all_layers = []\n",
    "\n",
    "        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.1)\n",
    "        config = tf.ConfigProto(gpu_options=gpu_options)\n",
    "        config.gpu_options.allow_growth = True\n",
    "\n",
    "        self.sess = tf.Session(config=config)\n",
    "\n",
    "        if not file_to_load:\n",
    "            self.X_placeholder = tf.placeholder(tf.float32, [None, 50, 4],name='X_placeholder')\n",
    "            self.Y_placeholder = tf.placeholder(tf.float32, [None, 2],name='Y_placeholder')\n",
    "            self.loaded = False\n",
    "            self.nn = None\n",
    "        else:\n",
    "            self.loaded = True\n",
    "            self._loadNetworkParameters('models/'+file_to_load)\n",
    "            self.X_placeholder = tf.get_default_graph().get_tensor_by_name('X_placeholder:0')\n",
    "            self.Y_placeholder = tf.get_default_graph().get_tensor_by_name('Y_placeholder:0')\n",
    "            self.predictions_softmax = tf.get_default_graph().get_tensor_by_name('softmax_prediction:0')\n",
    "\n",
    "\n",
    "    def addInputLayer(self):\n",
    "        assert len(self.all_layers) == 0, 'The input layer should be the first layer of the network, and can only be added once.'\n",
    "        self.all_layers.append(('Input layer','',self.X_placeholder))\n",
    "\n",
    "\n",
    "    def addConvLayer(self, num_of_filters, filter_width, zero_padding = True):\n",
    "        assert len(self.all_layers) > 0 and self.all_layers[0][0].startswith('Input layer')\n",
    "        assert zero_padding in (True,False), 'zero_padding should be True or False (boolean)'\n",
    "        assert 0 < num_of_filters < 500, 'The number of filters specified should be a positive number, smaller than 500'\n",
    "        assert 0 < filter_width < 64, 'The width of your filters should be a positive number, smaller than 64'\n",
    "        assert len(self.all_layers)+1 < 21, 'The total amount of layers should be at most 20'\n",
    "        assert 'Fully-connected layer' not in [typ for typ,_,_ in self.all_layers], 'You cannot add a convolutional layer after a fully-connected layer'\n",
    "        assert 'Softmax (output) layer' not in [typ for typ,_,_ in self.all_layers], 'You cannot add a convolutional layer after a softmax layer'\n",
    "        prev_width = self.all_layers[-1][-1].shape[1]\n",
    "        assert zero_padding or prev_width >= filter_width, 'You cannot add a (non-zeropadded) convolution of width {} when the previous layer has an output width of {}'.format(filter_width,prev_width)\n",
    "        self.all_layers.append(('Convolutional layer',\n",
    "                                '{} filters, width {}, {}zero padding, with ReLU'.format(num_of_filters,\n",
    "                                                                                         filter_width,\n",
    "                                                                                         'no ' if not zero_padding else ''),\n",
    "                                tf.layers.conv1d(self.all_layers[-1][-1],\n",
    "                                                 filters=num_of_filters,\n",
    "                                                 kernel_size=filter_width,\n",
    "                                                 activation=tf.nn.relu,\n",
    "                                                 padding='same' if zero_padding else 'valid')))\n",
    "\n",
    "    def addMaxPoolLayer(self, pool_size):\n",
    "        assert len(self.all_layers) > 0 and self.all_layers[0][0].startswith('Input layer')\n",
    "        assert 'Fully-connected layer' not in [typ for typ,_,_ in self.all_layers], 'You cannot add a pooling layer after a fully-connected layer'\n",
    "        assert 'Softmax (output) layer' not in [typ for typ,_,_ in self.all_layers], 'You cannot add a pooling layer after a softmax layer'\n",
    "        assert len(self.all_layers)+1 < 21, 'The total amount of layers should be at most 20'\n",
    "        assert 0 < pool_size < 50, 'The pool size should be lower than 50'\n",
    "        prev_width = self.all_layers[-1][-1].shape[1]\n",
    "        assert prev_width >= pool_size, 'You cannot add a pooling layer with pool size {} when the previous layer has an output width of {}'.format(pool_size,prev_width)\n",
    "        self.all_layers.append(('Max pooling layer',\n",
    "                                'pool size {}'.format(pool_size),\n",
    "                                tf.layers.max_pooling1d(self.all_layers[-1][-1],\n",
    "                                                        pool_size=pool_size,\n",
    "                                                        strides=pool_size)))\n",
    "    \n",
    "    def addFullyConnectedLayer(self,num_of_neurons):\n",
    "        assert len(self.all_layers) > 0 and self.all_layers[0][0].startswith('Input layer')\n",
    "        assert 'Softmax (output) layer' not in [typ for typ,_,_ in self.all_layers], 'You cannot add a fully-connected layer after a softmax layer'\n",
    "        assert len(self.all_layers)+1 < 21, 'The total amount of layers should be at most 20'\n",
    "        assert 0 < num_of_neurons < 1000, 'The amount of neurons in this layer should be a positive number, lower than 2000'\n",
    "        if len(self.all_layers[-1][-1].shape) > 2:\n",
    "            self.all_layers.append(('Flatten layer',\n",
    "                                    '',\n",
    "                                   tf.layers.flatten(self.all_layers[-1][-1])))\n",
    "        self.all_layers.append(('Fully-connected layer',\n",
    "                                '{} neurons, with ReLU'.format(num_of_neurons),\n",
    "                                tf.layers.dense(self.all_layers[-1][-1],num_of_neurons)))\n",
    "\n",
    "   \n",
    "    def addOutputLayer(self):\n",
    "        assert len(self.all_layers) > 0 and self.all_layers[0][0].startswith('Input layer')\n",
    "        assert 'Softmax (output) layer' not in [typ for typ,_,_ in self.all_layers], 'You cannot add a softmax (output) layer after a softmax layer'\n",
    "        assert len(self.all_layers)+1 < 21, 'The total amount of layers should be at most 20'\n",
    "        if len(self.all_layers[-1][-1].shape) > 2:\n",
    "            self.all_layers.append(('Flatten layer',\n",
    "                                    '',\n",
    "                                    tf.contrib.layers.flatten(self.all_layers[-1][-1])))\n",
    "        \n",
    "        self.all_layers.append(('Softmax (output) layer',\n",
    "                                '2 neurons',\n",
    "                                tf.layers.dense(self.all_layers[-1][-1], 2,name='logits')))\n",
    "   \n",
    "    def printDetails(self):\n",
    "        print('####################################')\n",
    "        print('Network information:')\n",
    "        # count all parameters:\n",
    "        total_parameters = 0\n",
    "        # iterating over all variables\n",
    "        for variable in tf.trainable_variables():\n",
    "            local_parameters = 1\n",
    "            shape = variable.get_shape()  # getting shape of a variable\n",
    "            for i in shape:\n",
    "                local_parameters *= i.value  # mutiplying dimension values\n",
    "            total_parameters += local_parameters\n",
    "        print('This network has {} trainable parameters.'.format(total_parameters))\n",
    "\n",
    "        for i,(name,info,l) in enumerate(self.all_layers):\n",
    "            try:\n",
    "                print('{: >2d}. {:23} {:50} -> Output size: {}'.format(i, name, info, l.shape))\n",
    "            except AttributeError:\n",
    "                pass\n",
    "        print('')\n",
    "        print('####################################')\n",
    "\n",
    "\n",
    "   \n",
    "    def train(self, trainX, trainY, validX, validY, n_epochs):\n",
    "        print('####################################')\n",
    "        assert 'Input layer' in [typ for typ,_,_ in self.all_layers], 'You cannot train a model without an input layer'\n",
    "        assert 'Softmax (output) layer' in [typ for typ,_,_ in self.all_layers], 'You cannot train a model without an output layer'\n",
    "        assert self.loaded == False, 'You can not (re)train a model loaded from a file.'\n",
    "        assert 1 < n_epochs < 100, 'The number of epochs should be greater than 1 and lower than 100'\n",
    "        assert all(type(l) == list for l in (trainX, trainY, validX, validY)), 'trainX, trainY, validX and validY should all be lists'\n",
    "        assert all(len(l) > 0 for l in (trainX, trainY, validX, validY)), 'trainX, trainY, validX and validY should not be empty'\n",
    "\n",
    "        assert len(trainX) == len(trainY), 'trainX and trainY should have the same amount of samples'\n",
    "        assert len(trainX[0]) == 50 and len(trainX[0][0]) == 4 and type(trainX[0][0][0]) == int, 'trainX should have size (_, 200, 4) and should contain integers'\n",
    "        assert type(trainY[0]) == int, 'trainY should have length n (for n sequences) and should contain integers'\n",
    "\n",
    "        assert len(validX) == len(validY), 'validX and validY should have the same amount of samples'\n",
    "        assert len(validX[0]) == 50 and len(validX[0][0]) == 4 and type(validX[0][0][0]) == int, 'validX should have size (_, 200, 4) and should contain integers'\n",
    "        assert type(validY[0]) == int, 'validY should have length n (for n sequences) and should contain integers'\n",
    "\n",
    "        self._prepare_training()\n",
    "\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        self.sess.run(tf.local_variables_initializer())\n",
    "        train_dataset = _Dataset(trainX, trainY)\n",
    "        valid_dataset = _Dataset(validX, validY)\n",
    "        self._printOutputClasses(train_dataset,'training')\n",
    "        self._printOutputClasses(valid_dataset,'validation')\n",
    "\n",
    "        best_valid_score = 999999\n",
    "        print()\n",
    "        print(' {:^5} | {:^14} | {:^14} | {:^11} | {:^11} | {:^8} '.format('epoch','train cost','valid cost','train acc','valid acc','time'))\n",
    "        print('-{:-^6}+{:-^16}+{:-^16}+{:-^13}+{:-^13}+{:-^9}-'.format('','','','','',''))\n",
    "\n",
    "        tr_cost, tr_acc = self._evaluateSet(train_dataset)\n",
    "        va_cost, va_acc = self._evaluateSet(valid_dataset)\n",
    "        print(' {:5d} |   {:2.8f}   |   {:2.8f}   |  {:1.7f}  | {:1.7f}  | {:4.2f}s '.format(0,tr_cost,tr_acc,va_cost,va_acc,0))\n",
    "\n",
    "        for epoch in range(1,n_epochs+1):\n",
    "            epoch_start_time = time.time()\n",
    "            epoch_finished = False\n",
    "            while not epoch_finished:\n",
    "                batch_x, batch_y, epoch_finished = train_dataset.next_batch(256)\n",
    "                self.sess.run(self.train_op, feed_dict={self.X_placeholder: batch_x, self.Y_placeholder: batch_y})\n",
    "            tr_cost, tr_acc = self._evaluateSet(train_dataset)\n",
    "            va_cost, va_acc = self._evaluateSet(valid_dataset)\n",
    "\n",
    "            if va_cost < best_valid_score:\n",
    "                best_valid_score = va_cost\n",
    "                message = '-> model selected'\n",
    "                self._storeNetworkParameters('models/tmp')\n",
    "            else:\n",
    "                message = ''\n",
    "            print(' {:5d} |   {:2.8f}   |   {:2.8f}   |  {:1.7f}  | {:1.7f}  | {:4.2f}s {}'.format(epoch,tr_cost,va_cost,tr_acc,va_acc,time.time()-epoch_start_time,message))\n",
    "\n",
    "        self._loadNetworkParameters('models/tmp')\n",
    "        print('Finished training')\n",
    "        print('####################################')\n",
    "\n",
    "    \n",
    "    def generatePredictions(self, testX):\n",
    "        assert len(testX[0]) == 50 and len(testX[0][0]) == 4 and type(testX[0][0][0]) == int, 'testX should have size (_, 200, 4) and should contain integers'\n",
    "        assert self.loaded or 'Input layer' in [typ for typ,_,_ in self.all_layers], 'You cannot test a model without an input layer'\n",
    "        assert self.loaded or 'Softmax (output) layer' in [typ for typ,_,_ in self.all_layers], 'You cannot test a model without an output layer'\n",
    "        # assert input and output layer\n",
    "        all_preds = []\n",
    "        for i in range(math.ceil(len(testX)/256)):\n",
    "            batch_x = np.asarray(testX[i*256:(i+1)*256])\n",
    "            preds = self.sess.run(self.predictions_softmax,feed_dict={self.X_placeholder:batch_x})\n",
    "            for i in range(len(preds)):\n",
    "                all_preds.append((preds[i][0],preds[i][1]))\n",
    "        return all_preds\n",
    "\n",
    "  \n",
    "    def saveModel(self, file_to_save_to):\n",
    "        assert 'Input layer' in [typ for typ,_,_ in self.all_layers], 'You cannot save a model without an input layer'\n",
    "        assert 'Softmax (output) layer' in [typ for typ,_,_ in self.all_layers], 'You cannot save a model without an output layer'\n",
    "        # assert input and output layer\n",
    "        assert not self.loaded, 'You cannot save a loaded model again.'\n",
    "        self._storeNetworkParameters('models/'+file_to_save_to)\n",
    "\n",
    "    def _prepare_training(self):\n",
    "        # assert all layers -1 == output layer\n",
    "        gs = tf.train.get_or_create_global_step()\n",
    "        self.predictions_softmax = tf.nn.softmax(self.all_layers[-1][-1],name='softmax_prediction')\n",
    "\n",
    "        self.cost_f = tf.losses.softmax_cross_entropy(onehot_labels=self.Y_placeholder, logits=self.all_layers[-1][-1])\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "        self.train_op = self.optimizer.minimize(loss=self.cost_f,global_step=gs)\n",
    "\n",
    "        self.acc_f, self.acc_op = tf.metrics.accuracy(labels=tf.argmax(self.Y_placeholder, axis=1),predictions=tf.argmax(self.predictions_softmax, axis=1),name='metric_acc')\n",
    "        self.metric_var_initializer = tf.variables_initializer(var_list=tf.get_collection(tf.GraphKeys.LOCAL_VARIABLES, scope='metric'))\n",
    "\n",
    "    def _evaluateSet(self, dataset):\n",
    "        self.sess.run(self.metric_var_initializer)\n",
    "        costs = []\n",
    "        batches_done = False\n",
    "        while not batches_done:\n",
    "            batch_x, batch_y, epoch_finished = dataset.next_batch(256)\n",
    "\n",
    "            cost_batch = self.sess.run(self.cost_f, feed_dict={self.X_placeholder: batch_x,self.Y_placeholder: batch_y})\n",
    "            _ = self.sess.run([self.acc_op], feed_dict={self.X_placeholder: batch_x,self.Y_placeholder: batch_y})\n",
    "            costs.extend([cost_batch] * len(batch_y))\n",
    "\n",
    "            if epoch_finished:\n",
    "                batches_done = True\n",
    "\n",
    "        accuracy = self.sess.run([self.acc_f])[0]\n",
    "        return np.average(costs),accuracy\n",
    "\n",
    "    def _printOutputClasses(self, dataset, label):\n",
    "        print()\n",
    "        counts = dataset.getClassCounts()\n",
    "        print('Number of {} examples: {}'.format(label,int(np.sum(counts))))\n",
    "        if len(counts) > 1:\n",
    "            print('Distribution of the {} set:'.format(label))\n",
    "            for i in range(min(10,len(counts))):\n",
    "                print('  # elements of class {} = {}'.format(i,int(counts[i])))\n",
    "\n",
    "    def _storeNetworkParameters(self, saveToDir):\n",
    "        try:\n",
    "            saver = tf.train.Saver()\n",
    "            if not os.path.exists(saveToDir):\n",
    "                os.makedirs(saveToDir)\n",
    "            saver.save(self.sess,saveToDir+'/'+saveToDir[saveToDir.rfind('/')+1:])\n",
    "        except Exception:\n",
    "            print('SOMETHING WENT WRONG WITH STORING SHIT JASPER!! ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "            print(sys.exc_info())\n",
    "            print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "\n",
    "    def _loadNetworkParameters(self, saveToDir):\n",
    "        filename = saveToDir+'/'+saveToDir[saveToDir.rfind('/')+1:]\n",
    "        if self.loaded:\n",
    "            saver = tf.train.import_meta_graph(filename+'.meta')\n",
    "        else:\n",
    "            saver = tf.train.Saver()\n",
    "        saver.restore(self.sess, tf.train.latest_checkpoint(saveToDir))\n",
    "\n",
    "\n",
    "class _Dataset:\n",
    "\n",
    "    def __init__(self,x_data,y_data=None):\n",
    "        if isinstance(x_data,list):\n",
    "            x_data = np.asarray(x_data)\n",
    "\n",
    "        self.index_in_epoch = 0\n",
    "        self.x_data = x_data\n",
    "        self.num_samples = x_data.shape[0]\n",
    "\n",
    "        if y_data:\n",
    "            if isinstance(y_data,list):\n",
    "                y_data = self._convertY(y_data)\n",
    "                self.y_data = y_data\n",
    "        else:\n",
    "            self.y_data = []\n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "\n",
    "    def getClassCounts(self):\n",
    "        return np.sum(self.y_data,axis=0)\n",
    "\n",
    "    def _convertY(self, y_data):\n",
    "        out = np.zeros((len(y_data),2))\n",
    "        for i,cl in enumerate(y_data):\n",
    "            out[i][cl] = 1\n",
    "        return out\n",
    "\n",
    "    def next_batch(self,batch_size):\n",
    "        start = self.index_in_epoch\n",
    "        end = self.index_in_epoch + batch_size\n",
    "\n",
    "        if start == 0:\n",
    "            idx = np.arange(0, self.num_samples)  # get all possible indexes\n",
    "            np.random.shuffle(idx)  # shuffle indexes\n",
    "            self.x_data = self.x_data[idx]\n",
    "            if len(self.y_data) > 0:\n",
    "                self.y_data = self.y_data[idx]\n",
    "\n",
    "        if end < self.num_samples:\n",
    "            self.index_in_epoch = end\n",
    "            return self.x_data[start:end], self.y_data[start:end], False # epoch finished = False\n",
    "        else:\n",
    "            self.index_in_epoch = 0\n",
    "            return self.x_data[start:], self.y_data[start:], True #epoch finished = True\n",
    "\n",
    "\n",
    "    def stepsInEpoch(self,batch_size):\n",
    "        return math.ceil(len(self) / batch_size)\n",
    "\n",
    "    def getX(self):\n",
    "        return self.x_data\n",
    "\n",
    "    def getSequenceLength(self):\n",
    "        return len(self.x_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_network():\n",
    "    con_model = NetworkModel()\n",
    "    con_model.addInputLayer()\n",
    "    con_model.addConvLayer(10, 7)\n",
    "    con_model.addMaxPoolLayer(5)\n",
    "    con_model.addConvLayer(20, 5)\n",
    "    con_model.addMaxPoolLayer(5)\n",
    "    con_model.addFullyConnectedLayer(15)\n",
    "    con_model.addOutputLayer()\n",
    "    return con_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################\n",
      "Network information:\n",
      "This network has 1957 trainable parameters.\n",
      " 0. Input layer                                                                -> Output size: (?, 50, 4)\n",
      " 1. Convolutional layer     10 filters, width 7, zero padding, with ReLU       -> Output size: (?, 50, 10)\n",
      " 2. Max pooling layer       pool size 5                                        -> Output size: (?, 10, 10)\n",
      " 3. Convolutional layer     20 filters, width 5, zero padding, with ReLU       -> Output size: (?, 10, 20)\n",
      " 4. Max pooling layer       pool size 5                                        -> Output size: (?, 2, 20)\n",
      " 5. Flatten layer                                                              -> Output size: (?, 40)\n",
      " 6. Fully-connected layer   15 neurons, with ReLU                              -> Output size: (?, 15)\n",
      " 7. Softmax (output) layer  2 neurons                                          -> Output size: (?, 2)\n",
      "\n",
      "####################################\n"
     ]
    }
   ],
   "source": [
    "cnn = conv_network()\n",
    "cnn.printDetails()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Обучение нейронной сети: результаты\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################\n",
      "\n",
      "Number of training examples: 24556\n",
      "Distribution of the training set:\n",
      "  # elements of class 0 = 12270\n",
      "  # elements of class 1 = 12286\n",
      "\n",
      "Number of validation examples: 5262\n",
      "Distribution of the validation set:\n",
      "  # elements of class 0 = 2616\n",
      "  # elements of class 1 = 2646\n",
      "\n",
      " epoch |   train cost   |   valid cost   |  train acc  |  valid acc  |   time   \n",
      "-------+----------------+----------------+-------------+-------------+----------\n",
      "     0 |   0.91788054   |   0.50032580   |  0.9166221  | 0.5030407  | 0.00s \n",
      "     1 |   0.69460064   |   0.69781357   |  0.5057827  | 0.4800456  | 1.83s -> model selected\n",
      "     2 |   0.69388270   |   0.69774669   |  0.5067601  | 0.4775751  | 1.81s -> model selected\n",
      "     3 |   0.69342232   |   0.69727975   |  0.5081039  | 0.4752946  | 1.83s -> model selected\n",
      "     4 |   0.69296867   |   0.69721979   |  0.5115247  | 0.4663626  | 1.81s -> model selected\n",
      "     5 |   0.69267505   |   0.69751149   |  0.5134386  | 0.4663626  | 1.61s \n",
      "     6 |   0.69258529   |   0.69755781   |  0.5122170  | 0.4629419  | 1.62s \n",
      "     7 |   0.69267374   |   0.69803053   |  0.5125428  | 0.4709236  | 1.73s \n",
      "     8 |   0.69245803   |   0.69834697   |  0.5151491  | 0.4604713  | 1.71s \n",
      "     9 |   0.69212860   |   0.69784290   |  0.5188549  | 0.4528696  | 1.66s \n",
      "    10 |   0.69195312   |   0.69827455   |  0.5222349  | 0.4456480  | 1.46s \n",
      "INFO:tensorflow:Restoring parameters from models/tmp/tmp\n",
      "Finished training\n",
      "####################################\n"
     ]
    }
   ],
   "source": [
    "cnn.train(X_train, y_train, X_val, y_val, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluating the results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(preds,labs):\n",
    "    tp,tn,fn,fp = 0,0,0,0\n",
    "    for (_,p),l in zip(preds,labs):\n",
    "        if p >= .5 and l == 1:\n",
    "            tp += 1\n",
    "        elif p < .5 and l == 1:\n",
    "            fn += 1\n",
    "        elif p >= .5 and l == 0:\n",
    "            fp += 1\n",
    "        else:\n",
    "            tn += 1\n",
    "    return tp / (tp + fn)\n",
    "\n",
    "\n",
    "def precision(preds,labs):\n",
    "    tp,tn,fn,fp = 0,0,0,0\n",
    "    for (_,p),l in zip(preds,labs):\n",
    "        if p >= .5 and l == 1:\n",
    "            tp += 1\n",
    "        elif p < .5 and l == 1:\n",
    "            fn += 1\n",
    "        elif p >= .5 and l == 0:\n",
    "            fp += 1\n",
    "        else:\n",
    "            tn += 1\n",
    "    return tp / (tp + fp)\n",
    "\n",
    "def f1(preds,labs):\n",
    "    r,p = recall(preds,labs), precision(preds,labs)\n",
    "    return 2 * r * p / (r + p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of the recall metrics is 0.5832055214723927\n",
      "Value of the precision metrics is 0.4796594134342479\n",
      "Value of the f1 metrics is 0.5263886485551134\n"
     ]
    }
   ],
   "source": [
    "pred = cnn.generatePredictions(X_test)\n",
    "\n",
    "print('Value of the recall metrics is', recall(pred,y_test))\n",
    "print('Value of the precision metrics is', precision(pred,y_test))\n",
    "print('Value of the f1 metrics is', f1(pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Другой интервал"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "magic_function(\"positive.bed\", \"pos_cut.bed\", SUB_INTERVAL)\n",
    "magic_function(\"negative.bed\", \"neg_cut.bed\", SUB_INTERVAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!twoBitToFa http://hgdownload.cse.ucsc.edu/gbdb/hg19/hg19.2bit -bed=neg_cut.bed gt_negative.fa\n",
    "!twoBitToFa http://hgdownload.cse.ucsc.edu/gbdb/hg19/hg19.2bit -bed=pos_cut.bed gt_positive.fa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################\n",
      "\n",
      "Number of training examples: 139140\n",
      "Distribution of the training set:\n",
      "  # elements of class 0 = 136558\n",
      "  # elements of class 1 = 2582\n",
      "\n",
      "Number of validation examples: 29816\n",
      "Distribution of the validation set:\n",
      "  # elements of class 0 = 29278\n",
      "  # elements of class 1 = 538\n",
      "\n",
      " epoch |   train cost   |   valid cost   |  train acc  |  valid acc  |   time   \n",
      "-------+----------------+----------------+-------------+-------------+----------\n",
      "     0 |   0.68015140   |   0.58398014   |  0.6790285  | 0.5925677  | 0.00s \n",
      "     1 |   0.08841711   |   0.08665936   |  0.9814432  | 0.9819560  | 9.67s -> model selected\n",
      "     2 |   0.08159179   |   0.08095119   |  0.9814432  | 0.9819560  | 10.37s -> model selected\n",
      "     3 |   0.07879434   |   0.07883994   |  0.9814072  | 0.9818889  | 10.43s -> model selected\n",
      "     4 |   0.07733566   |   0.07837177   |  0.9814216  | 0.9819224  | 11.30s -> model selected\n",
      "     5 |   0.07570811   |   0.07763978   |  0.9817163  | 0.9821572  | 11.76s -> model selected\n",
      "     6 |   0.07318526   |   0.07636562   |  0.9817019  | 0.9820902  | 10.12s -> model selected\n",
      "     7 |   0.07015219   |   0.07487611   |  0.9828302  | 0.9829957  | 11.54s -> model selected\n",
      "     8 |   0.06941865   |   0.07465424   |  0.9822266  | 0.9825597  | 11.05s -> model selected\n",
      "     9 |   0.07194813   |   0.07793807   |  0.9820468  | 0.9822578  | 11.60s \n",
      "    10 |   0.06638768   |   0.07320013   |  0.9830890  | 0.9831969  | 10.46s -> model selected\n",
      "INFO:tensorflow:Restoring parameters from models/tmp/tmp\n",
      "Finished training\n",
      "####################################\n",
      "Value of the recall metrics is 0.11367673179396093\n",
      "Value of the precision metrics is 0.7529411764705882\n",
      "Value of the f1 metrics is 0.19753086419753088\n"
     ]
    }
   ],
   "source": [
    "X_1, y_1 = readInputs(\"gt_positive.fa\", \"gt_negative.fa\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_1, y_1, test_size=0.3, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "cnn = conv_network()\n",
    "cnn.train(X_train, y_train, X_val, y_val, 10)\n",
    "pred = cnn.generatePredictions(X_test)\n",
    "\n",
    "print('Value of the recall metrics is', recall(pred,y_test))\n",
    "print('Value of the precision metrics is', precision(pred,y_test))\n",
    "print('Value of the f1 metrics is', f1(pred,y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
